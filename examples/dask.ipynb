{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Working with IPython and dask.distributed\n",
    "\n",
    "[dask.distributed](https://distributed.readthedocs.io) is a cool library for doing distributed execution. You should check it out, if you haven't already.\n",
    "\n",
    "Assuming you already have an IPython cluster running:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2, 3]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import ipyparallel as ipp\n",
    "rc = ipp.Client()\n",
    "rc.ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can turn your IPython cluster into a distributed cluster by calling `Client.become_dask()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"border: 2px solid white;\">\n",
       "<tr>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3>Client</h3>\n",
       "<ul>\n",
       "  <li><b>Scheduler: </b>tcp://192.168.1.19:51609\n",
       "</ul>\n",
       "</td>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3>Cluster</h3>\n",
       "<ul>\n",
       "  <li><b>Workers: </b>4</li>\n",
       "  <li><b>Cores: </b>4</li>\n",
       "  <li><b>Memory: </b>8.47 GB</li>\n",
       "</ul>\n",
       "</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<Client: scheduler='tcp://192.168.1.19:51609' processes=3 cores=3>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "executor = rc.become_dask(ncores=1)\n",
    "executor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will:\n",
    "\n",
    "1. start a Scheduler on the Hub\n",
    "2. start a Worker on each engine\n",
    "3. return an Executor, the distributed client API\n",
    "\n",
    "By default, distributed Workers will use threads to run on all cores of a machine. \n",
    "In this case, since I already have one *engine* per core,\n",
    "I tell distributed to run one core per Worker with `ncores=1`.\n",
    "\n",
    "We can now use our IPython cluster with distributed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'executor' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-0c7e9090465f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m-\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[0mA\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mexecutor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msquare\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[0mB\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mexecutor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mneg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mA\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[0mtotal\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mexecutor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msubmit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mB\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'executor' is not defined"
     ]
    }
   ],
   "source": [
    "from distributed import progress\n",
    "\n",
    "def square(x):\n",
    "    return x ** 2\n",
    "\n",
    "def neg(x):\n",
    "        return -x\n",
    "\n",
    "A = executor.map(square, range(1000))\n",
    "B = executor.map(neg, A)\n",
    "total = executor.submit(sum, B)\n",
    "progress(total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-332833500"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total.result()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I could also let distributed do its multithreading thing, and run one multi-threaded Worker per engine.\n",
    "\n",
    "First, I need to get a mapping of one engine per host:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'DESKTOP-9O127PB',\n",
       " 1: 'DESKTOP-9O127PB',\n",
       " 2: 'DESKTOP-9O127PB',\n",
       " 3: 'DESKTOP-9O127PB'}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import socket\n",
    "\n",
    "engine_hosts = rc[:].apply_async(socket.gethostname).get_dict()\n",
    "engine_hosts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I can reverse this mapping, to get a list of engines on each host:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'DESKTOP-9O127PB': [0, 1, 2, 3]}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "host_engines = {}\n",
    "for engine_id, host in engine_hosts.items():\n",
    "    if host not in host_engines:\n",
    "        host_engines[host] = []\n",
    "    host_engines[host].append(engine_id)\n",
    "\n",
    "host_engines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I can get one engine per host:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_engine_per_host = [ engines[0] for engines in host_engines.values()]\n",
    "one_engine_per_host"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Here's a concise, but more opaque version that does the same thing:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_engine_per_host = list({host:eid for eid,host in engine_hosts.items()}.values())\n",
    "one_engine_per_host"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I can now stop the first distributed cluster, and start a new one on just these engines, letting distributed allocate threads:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tornado.application - ERROR - Exception in callback <bound method Client._heartbeat of <Client: scheduler='tcp://192.168.1.19:63890' processes=24 cores=24>>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\tedal\\Anaconda3\\lib\\site-packages\\tornado\\ioloop.py\", line 1229, in _run\n",
      "    return self.callback()\n",
      "  File \"C:\\Users\\tedal\\Anaconda3\\lib\\site-packages\\distributed\\client.py\", line 900, in _heartbeat\n",
      "    self.scheduler_comm.send({'op': 'heartbeat-client'})\n",
      "  File \"C:\\Users\\tedal\\Anaconda3\\lib\\site-packages\\distributed\\batched.py\", line 117, in send\n",
      "    raise CommClosedError\n",
      "distributed.comm.core.CommClosedError\n",
      "tornado.application - ERROR - Exception in callback <bound method Client._heartbeat of <Client: scheduler='tcp://192.168.1.19:63890' processes=24 cores=24>>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\tedal\\Anaconda3\\lib\\site-packages\\tornado\\ioloop.py\", line 1229, in _run\n",
      "    return self.callback()\n",
      "  File \"C:\\Users\\tedal\\Anaconda3\\lib\\site-packages\\distributed\\client.py\", line 900, in _heartbeat\n",
      "    self.scheduler_comm.send({'op': 'heartbeat-client'})\n",
      "  File \"C:\\Users\\tedal\\Anaconda3\\lib\\site-packages\\distributed\\batched.py\", line 117, in send\n",
      "    raise CommClosedError\n",
      "distributed.comm.core.CommClosedError\n",
      "tornado.application - ERROR - Exception in callback <bound method Client._heartbeat of <Client: scheduler='tcp://192.168.1.19:63890' processes=24 cores=24>>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\tedal\\Anaconda3\\lib\\site-packages\\tornado\\ioloop.py\", line 1229, in _run\n",
      "    return self.callback()\n",
      "  File \"C:\\Users\\tedal\\Anaconda3\\lib\\site-packages\\distributed\\client.py\", line 900, in _heartbeat\n",
      "    self.scheduler_comm.send({'op': 'heartbeat-client'})\n",
      "  File \"C:\\Users\\tedal\\Anaconda3\\lib\\site-packages\\distributed\\batched.py\", line 117, in send\n",
      "    raise CommClosedError\n",
      "distributed.comm.core.CommClosedError\n",
      "tornado.application - ERROR - Exception in callback <bound method Client._heartbeat of <Client: scheduler='tcp://192.168.1.19:63890' processes=24 cores=24>>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\tedal\\Anaconda3\\lib\\site-packages\\tornado\\ioloop.py\", line 1229, in _run\n",
      "    return self.callback()\n",
      "  File \"C:\\Users\\tedal\\Anaconda3\\lib\\site-packages\\distributed\\client.py\", line 900, in _heartbeat\n",
      "    self.scheduler_comm.send({'op': 'heartbeat-client'})\n",
      "  File \"C:\\Users\\tedal\\Anaconda3\\lib\\site-packages\\distributed\\batched.py\", line 117, in send\n",
      "    raise CommClosedError\n",
      "distributed.comm.core.CommClosedError\n",
      "distributed.batched - INFO - Batched Comm Closed: in <closed TCP>: Stream is closed\n",
      "tornado.application - ERROR - Exception in callback <bound method Client._heartbeat of <Client: scheduler='tcp://192.168.1.19:63890' processes=24 cores=24>>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\tedal\\Anaconda3\\lib\\site-packages\\tornado\\ioloop.py\", line 1229, in _run\n",
      "    return self.callback()\n",
      "  File \"C:\\Users\\tedal\\Anaconda3\\lib\\site-packages\\distributed\\client.py\", line 900, in _heartbeat\n",
      "    self.scheduler_comm.send({'op': 'heartbeat-client'})\n",
      "  File \"C:\\Users\\tedal\\Anaconda3\\lib\\site-packages\\distributed\\batched.py\", line 117, in send\n",
      "    raise CommClosedError\n",
      "distributed.comm.core.CommClosedError\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table style=\"border: 2px solid white;\">\n",
       "<tr>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3>Client</h3>\n",
       "<ul>\n",
       "  <li><b>Scheduler: </b>tcp://192.168.1.19:50390\n",
       "</ul>\n",
       "</td>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3>Cluster</h3>\n",
       "<ul>\n",
       "  <li><b>Workers: </b>1</li>\n",
       "  <li><b>Cores: </b>1</li>\n",
       "  <li><b>Memory: </b>2.12 GB</li>\n",
       "</ul>\n",
       "</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<Client: scheduler='tcp://192.168.1.19:50390' processes=1 cores=1>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rc.stop_distributed()\n",
    "\n",
    "executor = rc.become_dask(one_engine_per_host)\n",
    "executor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And submit the same tasks again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d7fad09195f41d6b15b4a626b2d6253",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "A = executor.map(square, range(100))\n",
    "B = executor.map(neg, A)\n",
    "total = executor.submit(sum, B)\n",
    "progress(total)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Debugging distributed with IPython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tornado.application - ERROR - Exception in callback <bound method Client._heartbeat of <Client: scheduler='tcp://192.168.1.19:50390' processes=1 cores=1>>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\tedal\\Anaconda3\\lib\\site-packages\\tornado\\ioloop.py\", line 1229, in _run\n",
      "    return self.callback()\n",
      "  File \"C:\\Users\\tedal\\Anaconda3\\lib\\site-packages\\distributed\\client.py\", line 900, in _heartbeat\n",
      "    self.scheduler_comm.send({'op': 'heartbeat-client'})\n",
      "  File \"C:\\Users\\tedal\\Anaconda3\\lib\\site-packages\\distributed\\batched.py\", line 117, in send\n",
      "    raise CommClosedError\n",
      "distributed.comm.core.CommClosedError\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table style=\"border: 2px solid white;\">\n",
       "<tr>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3>Client</h3>\n",
       "<ul>\n",
       "  <li><b>Scheduler: </b>tcp://192.168.1.19:53103\n",
       "</ul>\n",
       "</td>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3>Cluster</h3>\n",
       "<ul>\n",
       "  <li><b>Workers: </b>1</li>\n",
       "  <li><b>Cores: </b>1</li>\n",
       "  <li><b>Memory: </b>2.12 GB</li>\n",
       "</ul>\n",
       "</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<Client: scheduler='tcp://192.168.1.19:53103' processes=1 cores=1>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tornado.application - ERROR - Exception in callback functools.partial(<function wrap.<locals>.null_wrapper at 0x00000167A97E9488>, <Future finished exception=CommClosedError('in <closed TCP>: Stream is closed')>)\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\tedal\\Anaconda3\\lib\\site-packages\\distributed\\comm\\tcp.py\", line 177, in read\n",
      "    n_frames = yield stream.read_bytes(8)\n",
      "  File \"C:\\Users\\tedal\\Anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 1133, in run\n",
      "    value = future.result()\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\tedal\\Anaconda3\\lib\\site-packages\\tornado\\ioloop.py\", line 758, in _run_callback\n",
      "    ret = callback()\n",
      "  File \"C:\\Users\\tedal\\Anaconda3\\lib\\site-packages\\tornado\\stack_context.py\", line 300, in null_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"C:\\Users\\tedal\\Anaconda3\\lib\\site-packages\\tornado\\ioloop.py\", line 779, in _discard_future_result\n",
      "    future.result()\n",
      "  File \"C:\\Users\\tedal\\Anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 1141, in run\n",
      "    yielded = self.gen.throw(*exc_info)\n",
      "  File \"C:\\Users\\tedal\\Anaconda3\\lib\\site-packages\\distributed\\diagnostics\\progressbar.py\", line 232, in listen\n",
      "    self.client else None)\n",
      "  File \"C:\\Users\\tedal\\Anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 1133, in run\n",
      "    value = future.result()\n",
      "  File \"C:\\Users\\tedal\\Anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 1141, in run\n",
      "    yielded = self.gen.throw(*exc_info)\n",
      "  File \"C:\\Users\\tedal\\Anaconda3\\lib\\site-packages\\distributed\\comm\\tcp.py\", line 198, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"C:\\Users\\tedal\\Anaconda3\\lib\\site-packages\\distributed\\comm\\tcp.py\", line 126, in convert_stream_closed_error\n",
      "    raise CommClosedError(\"in %s: %s\" % (obj, exc))\n",
      "distributed.comm.core.CommClosedError: in <closed TCP>: Stream is closed\n",
      "tornado.application - ERROR - Exception in callback functools.partial(<function wrap.<locals>.null_wrapper at 0x00000167A972D598>, <Future finished exception=CommClosedError('in <closed TCP>: Stream is closed')>)\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\tedal\\Anaconda3\\lib\\site-packages\\distributed\\comm\\tcp.py\", line 177, in read\n",
      "    n_frames = yield stream.read_bytes(8)\n",
      "  File \"C:\\Users\\tedal\\Anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 1133, in run\n",
      "    value = future.result()\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\tedal\\Anaconda3\\lib\\site-packages\\tornado\\ioloop.py\", line 758, in _run_callback\n",
      "    ret = callback()\n",
      "  File \"C:\\Users\\tedal\\Anaconda3\\lib\\site-packages\\tornado\\stack_context.py\", line 300, in null_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"C:\\Users\\tedal\\Anaconda3\\lib\\site-packages\\tornado\\ioloop.py\", line 779, in _discard_future_result\n",
      "    future.result()\n",
      "  File \"C:\\Users\\tedal\\Anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 1141, in run\n",
      "    yielded = self.gen.throw(*exc_info)\n",
      "  File \"C:\\Users\\tedal\\Anaconda3\\lib\\site-packages\\distributed\\diagnostics\\progressbar.py\", line 232, in listen\n",
      "    self.client else None)\n",
      "  File \"C:\\Users\\tedal\\Anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 1133, in run\n",
      "    value = future.result()\n",
      "  File \"C:\\Users\\tedal\\Anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 1141, in run\n",
      "    yielded = self.gen.throw(*exc_info)\n",
      "  File \"C:\\Users\\tedal\\Anaconda3\\lib\\site-packages\\distributed\\comm\\tcp.py\", line 198, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"C:\\Users\\tedal\\Anaconda3\\lib\\site-packages\\distributed\\comm\\tcp.py\", line 126, in convert_stream_closed_error\n",
      "    raise CommClosedError(\"in %s: %s\" % (obj, exc))\n",
      "distributed.comm.core.CommClosedError: in <closed TCP>: Stream is closed\n"
     ]
    }
   ],
   "source": [
    "rc.stop_distributed()\n",
    "\n",
    "executor = rc.become_dask(one_engine_per_host)\n",
    "executor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's set the %px magics to only run on our one engine per host:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "view = rc[one_engine_per_host]\n",
    "view.block = True\n",
    "view.activate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's submit some work that's going to fail somewhere in the middle:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'executor' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-848f6537366b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[0mshifted\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mexecutor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshift5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[0minverted\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mexecutor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minverse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshifted\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'executor' is not defined"
     ]
    }
   ],
   "source": [
    "from IPython.display import display\n",
    "from distributed import progress\n",
    "\n",
    "def shift5(x):\n",
    "    return x - 5\n",
    "\n",
    "def inverse(x):\n",
    "    return 1 / x\n",
    "\n",
    "shifted = executor.map(shift5, range(1, 10))\n",
    "inverted = executor.map(inverse, shifted)\n",
    "                       \n",
    "total = executor.submit(sum, inverted)\n",
    "display(progress(total))\n",
    "total.result()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see which task failed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<Future: status: error, key: inverse-f8907aa30adc310cc8168553500ca8bb>]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[ f for f in inverted if f.status == 'error' ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When IPython starts a worker on each engine,\n",
    "it stores it in the `distributed_worker` variable in the engine's namespace.\n",
    "This lets us query the worker interactively.\n",
    "\n",
    "We can check out the current data resident on each worker:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mOut[7:2]: \u001b[0m\n",
       "{'inverse-07072811957c38188d819607f8020bed': 0.3333333333333333,\n",
       " 'inverse-0994af96c984b7254e2437daa46df6c8': 1.0,\n",
       " 'inverse-1934b1ad8662540a6b1a321502d3d81e': 0.25,\n",
       " 'inverse-2e0af360f3e400c0360eaa3351e80a4d': -1.0,\n",
       " 'inverse-8ef20ef722160668e84ab435b8293751': -0.5,\n",
       " 'inverse-bee9906329afc3cb86cc241209453f56': -0.3333333333333333,\n",
       " 'inverse-cfd3e5b72a33fd2fa85c683107287cf9': -0.25,\n",
       " 'inverse-d9ed866e67ebc068f6561f9263c4cf73': 0.5,\n",
       " 'shift5-17c829bc866d38df11bb25ffc7ea887f': -3,\n",
       " 'shift5-3035396f215ce921eda38f8f36ca3e90': 4,\n",
       " 'shift5-4951afd99368d41997f42a2f823f566f': 2,\n",
       " 'shift5-5c9f9254c4a34e7571d53ee4839ea6f2': 1,\n",
       " 'shift5-8458d8715078405cb9dfed60d1c3d26a': -2,\n",
       " 'shift5-899e24c059f86698e06254cfd5f3f4ea': -1,\n",
       " 'shift5-9326e9993993cb1c08355c6e5b8e5970': -4,\n",
       " 'shift5-cabacfd5aaf525d183d932617b8eac5a': 0,\n",
       " 'shift5-e233bf13876414d6a0a4817695ac7ca1': 3}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%px\n",
    "dask_worker.data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Now that we can poke around with each Worker,\n",
    "we can have a slightly easier time figuring out what went wrong."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "widgets": {
   "state": {
    "0db2b058b609455fa55654e5e3565453": {
     "views": [
      {
       "cell_index": 24
      }
     ]
    },
    "58612800fe1d42058d0cbc83f0534655": {
     "views": [
      {
       "cell_index": 18
      }
     ]
    },
    "f4647eb4300e4eb6bcdae457df082cc7": {
     "views": [
      {
       "cell_index": 5
      }
     ]
    }
   },
   "version": "1.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
